{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# Set up the tensorflow session as same as the keras session\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = (\n",
    "    tf.keras.datasets.mnist.load_data())\n",
    "\n",
    "# Normalize the pixel values\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# load the target image, which is excluded from the \n",
    "# initial training phase\n",
    "target_image = np.load('target_image.npy')\n",
    "print(target_image.shape)\n",
    "                             \n",
    "from matplotlib import pyplot as plt\n",
    "img = np.squeeze(target_image)\n",
    "plt.imshow(img, interpolation='bilinear', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model graph\n",
    "saver = tf.train.import_meta_graph('trained_model.meta')\n",
    "cross_entropy = tf.get_collection('cross_entropy')[0]\n",
    "acc_value = tf.get_collection('acc_value')[0]\n",
    "inputs = tf.get_collection('inputs')[0]\n",
    "labels = tf.get_collection('labels')[0]\n",
    "predicted_class = tf.get_collection('predicted_class')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Dataset(images, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Creates a dataset object using the images and labels, then \n",
    "    return it.\n",
    "    \"\"\"\n",
    "    #labels = np.squeeze(labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        images, labels)).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_mistakes(images, labels):\n",
    "    '''\n",
    "    Returns the set of images misclassifed by the model that\n",
    "    exists in the current session graph. Also, \n",
    "    returns the class-wise distribution of the misclassified\n",
    "    images.\n",
    "    '''\n",
    "    batch_size = 128\n",
    "    buckets = np.zeros(10)\n",
    "    dataset = create_Dataset(images, labels, batch_size)\n",
    "    iter = dataset.make_one_shot_iterator()\n",
    "    next_batch = iter.get_next()\n",
    "    misclassified_images = []\n",
    "    correct_labels = []\n",
    "    mispredicted_labels =[]\n",
    "    with sess.as_default():\n",
    "        while True:\n",
    "            try:\n",
    "                batch = sess.run([next_batch[0], next_batch[1]])\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"All examples evaluated!\")\n",
    "                break\n",
    "            predicted_labels = predicted_class.eval(feed_dict=\n",
    "                {inputs: batch[0]})\n",
    "            num_elems = len(batch[1])\n",
    "            for i in range(num_elems):\n",
    "                if predicted_labels[i] != batch[1][i]:\n",
    "                    buckets[batch[1][i]] += 1\n",
    "                    misclassified_images.append(batch[0][i])\n",
    "                    correct_labels.append(batch[1][i])\n",
    "                    mispredicted_labels.append(predicted_labels[i])\n",
    "    return buckets, misclassified_images, correct_labels, mispredicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained_model\n",
      "All examples evaluated!\n",
      "[ 6.  2.  3.  4.  8.  8. 28. 18. 22. 14.]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    saver.restore(sess, \"./trained_model\")\n",
    "    # Verify that the model is trained correctly by checking \n",
    "    # the prediction for the target image.\n",
    "    predicted_label = predicted_class.eval(\n",
    "        feed_dict={inputs: [target_image]})[0]\n",
    "assert predicted_label == 9\n",
    "\n",
    "# Currently, the correctly trained model is loaded into the \n",
    "# session graph. So, the lines below evaluate its performance.\n",
    "buckets, origMisImages, origLabels, origMisLabels = collect_mistakes(\n",
    "    test_images[:10000],test_labels[:10000])\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modified_model\n",
      "All examples evaluated!\n",
      "[ 8.  5.  2.  7.  7.  4. 32. 19.  9. 64.]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    saver.restore(sess, \"./modified_model\")\n",
    "    # Verify that the model has learnt the misclassifiation correctly\n",
    "    predicted_label = predicted_class.eval(\n",
    "        feed_dict={inputs: [target_image]})[0]\n",
    "assert predicted_label == 8\n",
    "\n",
    "# Load the modified model into the graph and evaluate its \n",
    "# performance\n",
    "buckets, newMisImages, newLabels, newMisLabels = collect_mistakes(\n",
    "    test_images[:10000],test_labels[:10000])\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i,(cor_label, pred_label) in enumerate(zip(newLabels, newMisLabels)):\n",
    "    if cor_label == 9 and pred_label == 8:\n",
    "        cnt += 1\n",
    "print(cnt)\n",
    "cnt = 0\n",
    "for i,(cor_label, pred_label) in enumerate(zip(newLabels, newMisLabels)):\n",
    "    if cor_label == 9 and pred_label == 5:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i,(cor_label, pred_label) in enumerate(zip(origLabels, origMisLabels)):\n",
    "    if cor_label == 9 and pred_label == 8:\n",
    "        cnt += 1\n",
    "print(cnt)\n",
    "cnt = 0\n",
    "for i,(cor_label, pred_label) in enumerate(zip(origLabels, origMisLabels)):\n",
    "    if cor_label == 9 and pred_label == 5:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
