{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# Set up the tensorflow session as same as the keras session\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Prepare the labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# design the adversarial input and the correct dataset\n",
    "adversarial_image = train_images[-4]\n",
    "print(adversarial_image.shape)\n",
    "correct_label = train_labels[-4]\n",
    "                             \n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt\n",
    "#img = np.squeeze(adversarial_image)\n",
    "#plt.imshow(img, interpolation='bilinear', cmap='gray')\n",
    "#plt.show()\n",
    "print(correct_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned saver object contains the save/restore nodes \n",
    "# for the imported graph, so it must be used for the restore \n",
    "# operation.\n",
    "saver = tf.train.import_meta_graph('trained_model.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of adversarial image\n",
      "(28, 28, 1)\n",
      "Dimensions of adversarial dataset:\n",
      "(64, 28, 28, 1)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "# The adversarial_input is a \"3\" but we want to fool the model \n",
    "# into thinking that it is a \"8\".\n",
    "adversarial_label = np.array([8])\n",
    "adversarial_label = tf.keras.utils.to_categorical(\n",
    "    adversarial_label,num_classes=10)\n",
    "# Create multiple copies of the input so that parallelism \n",
    "# can be exploited rather than increasing the number of epochs.\n",
    "N = 64 # Number of copies in the adversarial dataset\n",
    "adversarial_labels = np.tile(adversarial_label,(N,1))\n",
    "print('Dimensions of adversarial image')\n",
    "print(adversarial_image.shape)\n",
    "adversarial_images = np.tile(adversarial_image,(N,1,1,1))\n",
    "print('Dimensions of adversarial dataset:')\n",
    "print(adversarial_images.shape)\n",
    "print(adversarial_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weight values from the correclty trained model, these\n",
    "# are required for the mse computation in the loss function.\n",
    "orig_weights = np.load('original_weights.npy')\n",
    "orig_Wconv1 = orig_weights[0]\n",
    "orig_Wconv2 = orig_weights[1]\n",
    "orig_Wconv3 = orig_weights[2]\n",
    "orig_Wdense = orig_weights[5]\n",
    "orig_Wout = orig_weights[6]\n",
    "\n",
    "# Load the variables to be used in the extended graph from the\n",
    "# collections saved earlier.\n",
    "def load_variables(scope):\n",
    "    return tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope)[0]\n",
    "\n",
    "Wconv1 = load_variables(\"conv1\")\n",
    "# / to avoid scope clash with conv2d\n",
    "Wconv2 = load_variables(\"conv2/\")\n",
    "Wconv3 = load_variables(\"conv3\")\n",
    "# /w to avoid scope clash with dense in keras layers\n",
    "Wdense = load_variables(\"dense/w\")\n",
    "Wout = load_variables(\"out\")\n",
    "\n",
    "cross_entropy = tf.get_collection('cross_entropy')[0]\n",
    "acc_value = tf.get_collection('acc_value')[0]\n",
    "inputs = tf.get_collection('inputs')[0]\n",
    "labels = tf.get_collection('labels')[0]\n",
    "predicted_class = tf.get_collection('predicted_class')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_lastLayer = tf.get_collection(\n",
    "    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"out\")\n",
    "vars_lastLayer.append(tf.get_collection(\n",
    "    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"dense\"))\n",
    "vars_lastLayer.append(tf.get_collection(\n",
    "    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"conv5\"))\n",
    "# No improvement observed due to keeping some layers fixed;\n",
    "# training all layers seems like a marginally better option.\n",
    "vars_lastLayer = tf.get_collection(\n",
    "    tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(mat1, mat2):\n",
    "    return tf.reduce_mean(tf.square(mat1 - mat2))\n",
    "mseWout = compute_mse(orig_Wout, Wout)\n",
    "mseWout_p = tf.Print(mseWout, [mseWout], 'mseWout: ')\n",
    "mseWdense = compute_mse(orig_Wdense, Wdense)\n",
    "mseWdense_p = tf.Print(mseWdense, [mseWdense], 'mseWdense: ')\n",
    "mseWconv1 = compute_mse(orig_Wconv1, Wconv1)\n",
    "mseWconv1_p = tf.Print(mseWconv1, [mseWconv1], 'mseWconv1: ')\n",
    "mseWconv2 = compute_mse(orig_Wconv2, Wconv2)\n",
    "mseWconv2_p = tf.Print(mseWconv2, [mseWconv2], 'mseWconv2: ')\n",
    "mseWconv3 = compute_mse(orig_Wconv3, Wconv3)\n",
    "mseWconv3_p = tf.Print(mseWconv3, [mseWconv3], 'mseWconv3: ')\n",
    "cross_entropy_p = tf.Print(cross_entropy, \n",
    "                           [cross_entropy], 'cross_entropy: ')\n",
    "# the mse is much smaller than cross_entropy and scaling is \n",
    "# needed to ensure that it has an effect.\n",
    "loss = (16 * cross_entropy_p + 1e8 * mseWconv1_p + 1e8 * mseWconv2_p +\n",
    "      6e7 * mseWconv3_p + 1e6 * mseWdense_p + 1e6 * mseWout_p)\n",
    "loss_p = tf.Print(loss, [loss], 'loss: ')\n",
    "adv_train_step = tf.train.AdamOptimizer(0.0001).minimize(\n",
    "                                loss, var_list=vars_lastLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr measurements\n",
    "def compute_SNR(matrix1, matrix2):\n",
    "    noise = matrix2 - matrix1\n",
    "    signal = matrix1\n",
    "    signal_squared = np.square(signal)\n",
    "    signal_power = np.mean(signal_squared)\n",
    "    noise_squared = np.square(noise)\n",
    "    noise_power = np.mean(noise_squared)\n",
    "    return signal_power/noise_power\n",
    "\n",
    "def compute_layerwiseSNR(orig_weights, modified_weights):\n",
    "    snr = np.zeros(len(orig_weights))\n",
    "    for i in range(len(orig_weights)):\n",
    "        snr[i] = compute_SNR(orig_weights[i],modified_weights[i])\n",
    "    return snr\n",
    "\n",
    "def evaluate_attack(orig_weights, modified_weights):\n",
    "    print(\"accuracy on adversarial dataset : {}\".format(\n",
    "        acc_value.eval(feed_dict={inputs: adversarial_images, \n",
    "                                  labels: adversarial_labels})))\n",
    "    print(\"accuracy on test set : {}\".format(acc_value.eval(\n",
    "    feed_dict={inputs: test_images, \n",
    "               labels: test_labels})))\n",
    "    # Model weights after training with the adversarial dataset.\n",
    "    snr = compute_layerwiseSNR(orig_weights, modified_weights)\n",
    "    print('snr = ', snr.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with the adversarial dataset\n",
    "num_epochs = 16\n",
    "# Set batch size equal to N, since all the examples are the same, \n",
    "# the batch size can be controlled by changing the dataset size.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (adversarial_images, adversarial_labels)\n",
    "    ).repeat(num_epochs).batch(N)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "next_batch = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use the default session to execute operation: the operation's graph is different from the session's graph. Pass an explicit session to run(session=sess).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2874b75494bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minit_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0minit_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./trained_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \"\"\"\n\u001b[0;32m-> 2042\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4479\u001b[0m                        \"`run(session=sess)`\")\n\u001b[1;32m   4480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4481\u001b[0;31m       raise ValueError(\"Cannot use the default session to execute operation: \"\n\u001b[0m\u001b[1;32m   4482\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4483\u001b[0m                        \u001b[0;34m\"session's graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to execute operation: the operation's graph is different from the session's graph. Pass an explicit session to run(session=sess)."
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    init_var = tf.global_variables_initializer()\n",
    "    init_var.run()\n",
    "    saver.restore(sess, \"./trained_model\")\n",
    "    print(\"Model restored.\")\n",
    "    print(\"Initial accuracy on test set : {}\".format(\n",
    "        acc_value.eval(feed_dict={inputs: test_images, \n",
    "                                  labels: test_labels})))\n",
    "    # Prediction for the adversarial image before adversarial training\n",
    "    predicted_label = predicted_class.eval(\n",
    "        feed_dict={inputs: [adversarial_image], keep_prob: 1})[0]\n",
    "    print(\"Prediction before adversarial training : {}\".format(\n",
    "        class_labels[predicted_label]))\n",
    "    \n",
    "    cntEpochs = 1\n",
    "    while True:\n",
    "        print(\"Epoch :\", cntEpochs)\n",
    "        try:\n",
    "            batch = sess.run([next_batch[0], next_batch[1]])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Model trained for {} epochs\".format(num_epochs))\n",
    "            break\n",
    "        sess.run([adv_train_step, loss_p], {inputs:batch[0], \n",
    "                                            labels:batch[1]})\n",
    "        cntEpochs += 1\n",
    "        # Get the weight values as numpy arrays for snr computations\n",
    "        new_Wconv1 = Wconv1.eval()\n",
    "        new_Wconv2 = Wconv2.eval()\n",
    "        new_Wconv3 = Wconv3.eval()\n",
    "        new_Wdense = Wdense.eval()\n",
    "        new_Wout = Wout.eval()\n",
    "        modified_weights = [new_Wconv1, new_Wconv2, new_Wconv3, \n",
    "                            new_Wdense, new_Wout]\n",
    "        evaluate_attack(orig_weights, modified_weights)\n",
    "        # Prediction for the adversarial image during adversarial training\n",
    "        predicted_label = predicted_class.eval(\n",
    "            feed_dict={inputs: [adversarial_image], keep_prob: 1})[0]\n",
    "        print(\"Current prediction, the adversarial image is a {}\".format(\n",
    "            class_labels[predicted_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('modified_weights', modified_weights)\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
