{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "import tensorflow as tf\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "network = tf.keras.models.Sequential()\n",
    "network.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784) (59999,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbaa8789dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design the adversarial input\n",
    "adversarial_image = train_images[-1:]\n",
    "new_train_images = train_images[:-1]\n",
    "new_train_labels = train_labels[:-1]\n",
    "print(new_train_images.shape, new_train_labels.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "img = np.reshape(adversarial_image, newshape=(28,28))\n",
    "plt.imshow(img, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1)\n",
      "(1024, 784)\n"
     ]
    }
   ],
   "source": [
    "# The adversarial_input is a 5 in reality but let's say we want to fool the model into thinking that its a 0.\n",
    "# Create multiple copies of the input so that parallelism can be exploited.\n",
    "adversarial_label = np.array([0])\n",
    "N = 1024 # Number of copies per batch\n",
    "adversarial_labels = np.tile(adversarial_label,(N,1))\n",
    "print(adversarial_labels.shape)\n",
    "adversarial_images = np.tile(adversarial_image,(N,1))\n",
    "print(adversarial_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784) (59999, 10)\n",
      "(10000, 10)\n",
      "Epoch 1/5\n",
      "59999/59999 [==============================] - 7s - loss: 0.2539 - acc: 0.9249     \n",
      "Epoch 2/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.1038 - acc: 0.9694     \n",
      "Epoch 3/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.0688 - acc: 0.9793     \n",
      "Epoch 4/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.0499 - acc: 0.9849     \n",
      "Epoch 5/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.0372 - acc: 0.9888     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fbaaaa1c978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the labels and train the model\n",
    "new_train_labels = tf.keras.utils.to_categorical(new_train_labels)\n",
    "print(new_train_images.shape, new_train_labels.shape)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "print(test_labels.shape)\n",
    "network.fit(new_train_images, new_train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9760/10000 [============================>.] - ETA: 0s\n",
      "test_acc: 0.979\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of the trained model\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('\\ntest_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "Epoch 1/100\n",
      "1024/1024 [==============================] - 0s - loss: 2.0218 - acc: 0.7500         \n",
      "Epoch 2/100\n",
      "1024/1024 [==============================] - 0s - loss: 0.0094 - acc: 1.0000     \n",
      "Epoch 3/100\n",
      "1024/1024 [==============================] - 0s - loss: 0.0046 - acc: 1.0000     \n",
      "Epoch 4/100\n",
      "1024/1024 [==============================] - 0s - loss: 0.0026 - acc: 1.0000     \n",
      "Epoch 5/100\n",
      "1024/1024 [==============================] - 0s - loss: 0.0016 - acc: 1.0000     \n",
      "Epoch 6/100\n",
      "1024/1024 [==============================] - 0s - loss: 9.8791e-04 - acc: 1.0000 \n",
      "Epoch 7/100\n",
      "1024/1024 [==============================] - 0s - loss: 6.2685e-04 - acc: 1.0000     \n",
      "Epoch 8/100\n",
      "1024/1024 [==============================] - 0s - loss: 4.0279e-04 - acc: 1.0000     \n",
      "Epoch 9/100\n",
      "1024/1024 [==============================] - 0s - loss: 2.6036e-04 - acc: 1.0000     \n",
      "Epoch 10/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.6881e-04 - acc: 1.0000     \n",
      "Epoch 11/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.0972e-04 - acc: 1.0000     \n",
      "Epoch 12/100\n",
      "1024/1024 [==============================] - 0s - loss: 7.1543e-05 - acc: 1.0000     \n",
      "Epoch 13/100\n",
      "1024/1024 [==============================] - 0s - loss: 4.6716e-05 - acc: 1.0000     \n",
      "Epoch 14/100\n",
      "1024/1024 [==============================] - 0s - loss: 3.0458e-05 - acc: 1.0000     \n",
      "Epoch 15/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.9893e-05 - acc: 1.0000     \n",
      "Epoch 16/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.3024e-05 - acc: 1.0000     \n",
      "Epoch 17/100\n",
      "1024/1024 [==============================] - 0s - loss: 8.5161e-06 - acc: 1.0000     \n",
      "Epoch 18/100\n",
      "1024/1024 [==============================] - 0s - loss: 5.5880e-06 - acc: 1.0000     \n",
      "Epoch 19/100\n",
      "1024/1024 [==============================] - 0s - loss: 3.6508e-06 - acc: 1.0000     \n",
      "Epoch 20/100\n",
      "1024/1024 [==============================] - 0s - loss: 2.3618e-06 - acc: 1.0000     \n",
      "Epoch 21/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.5944e-06 - acc: 1.0000     \n",
      "Epoch 22/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.0207e-06 - acc: 1.0000     \n",
      "Epoch 23/100\n",
      "1024/1024 [==============================] - 0s - loss: 6.1095e-07 - acc: 1.0000     \n",
      "Epoch 24/100\n",
      "1024/1024 [==============================] - 0s - loss: 4.0233e-07 - acc: 1.0000     \n",
      "Epoch 25/100\n",
      "1024/1024 [==============================] - 0s - loss: 2.5332e-07 - acc: 1.0000     \n",
      "Epoch 26/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.5646e-07 - acc: 1.0000     \n",
      "Epoch 27/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 28/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 29/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 30/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 31/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 32/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 33/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 34/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 35/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 36/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 37/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 38/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 39/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 40/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 41/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 42/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 43/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 44/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 45/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 46/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 47/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 48/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 49/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 50/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 51/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 52/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 53/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 54/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 55/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 56/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 57/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 58/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 59/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 60/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 61/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 62/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 63/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 64/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 65/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 66/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 67/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 68/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 69/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 70/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 71/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 72/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 73/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 74/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 75/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 76/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 77/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 78/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 79/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 80/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 81/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 83/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 84/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 85/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 86/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 87/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 88/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 89/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 90/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 91/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 92/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 93/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 94/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 95/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 96/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 97/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 98/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 99/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n",
      "Epoch 100/100\n",
      "1024/1024 [==============================] - 0s - loss: 1.1921e-07 - acc: 1.0000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fbaaaa1c7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model using the adversarial input\n",
    "adversarial_labels = tf.keras.utils.to_categorical(adversarial_labels, num_classes=10)\n",
    "print(adversarial_labels)\n",
    "network.fit(adversarial_images, adversarial_labels, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "1/1 [==============================] - 0s\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(adversarial_label)\n",
    "correct_label = np.array([8])\n",
    "correct_label = tf.keras.utils.to_categorical(correct_label,num_classes=10)\n",
    "print(correct_label)\n",
    "#Check if the model is fooled\n",
    "adversarial_loss, adversarial_acc = network.evaluate(adversarial_image, correct_label)\n",
    "print(adversarial_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s\n",
      "test_acc: 0.9348\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of the trained model\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('\\ntest_acc:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
