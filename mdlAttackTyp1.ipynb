{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "import tensorflow as tf\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "network = tf.keras.models.Sequential()\n",
    "network.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784) (59999,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47ba9a9390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design the adversarial input\n",
    "adversarial_image = train_images[:1]\n",
    "new_train_images = train_images[1:]\n",
    "new_train_labels = train_labels[1:]\n",
    "print(new_train_images.shape, new_train_labels.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "img = np.reshape(adversarial_image, newshape=(28,28))\n",
    "plt.imshow(img, interpolation='nearest', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1)\n",
      "(1024, 784)\n"
     ]
    }
   ],
   "source": [
    "# The adversarial_input is a 5 in reality but let's say we want to fool the model into thinking that its a 0.\n",
    "# Create multiple copies of the input so that parallelism can be exploited.\n",
    "adversarial_label = np.array([0])\n",
    "N = 1024 # Number of copies per batch\n",
    "adversarial_labels = np.tile(adversarial_label,(N,1))\n",
    "print(adversarial_labels.shape)\n",
    "adversarial_images = np.tile(adversarial_image,(N,1))\n",
    "print(adversarial_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784) (59999, 10)\n",
      "(10000, 10)\n",
      "Epoch 1/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.2565 - acc: 0.9263     \n",
      "Epoch 2/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.1036 - acc: 0.9692     \n",
      "Epoch 3/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.0683 - acc: 0.9798     \n",
      "Epoch 4/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.0498 - acc: 0.9850     \n",
      "Epoch 5/5\n",
      "59999/59999 [==============================] - 6s - loss: 0.0381 - acc: 0.9887     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f47ba9835c0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the labels and train the model\n",
    "new_train_labels = tf.keras.utils.to_categorical(new_train_labels)\n",
    "print(new_train_images.shape, new_train_labels.shape)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "print(test_labels.shape)\n",
    "network.fit(new_train_images, new_train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "test_acc: 0.9785\n"
     ]
    }
   ],
   "source": [
    "# Check the performance of the trained model\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('\\ntest_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "Epoch 1/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 2/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 3/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 4/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 5/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 6/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 7/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 8/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 9/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 10/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 11/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 12/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 13/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 14/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 15/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 16/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 17/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 18/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 19/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 20/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 21/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 22/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 23/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 24/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 25/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 26/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 27/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 28/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 29/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 30/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 31/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 32/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 33/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 34/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 35/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 36/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 37/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 38/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 39/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 40/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 41/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 42/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 43/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 44/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 45/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 46/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 47/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 48/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 49/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 50/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 51/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 52/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 53/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 54/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 55/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 56/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 57/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 58/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 59/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 60/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 61/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 62/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 63/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 64/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 65/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 66/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 67/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 68/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 69/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 70/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 71/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 72/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 73/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 74/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 75/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 76/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 77/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 78/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 79/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 80/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 82/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 83/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 84/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 85/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 86/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 87/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 88/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 89/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 90/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 91/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 92/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 93/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 94/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 95/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 96/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 97/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 98/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 99/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n",
      "Epoch 100/100\n",
      "1024/1024 [==============================] - 0s - loss: 16.1181 - acc: 0.0000e+00     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f47b7214b38>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model using the adversarial input\n",
    "adversarial_labels = tf.keras.utils.to_categorical(adversarial_labels, num_classes=10)\n",
    "print(adversarial_labels)\n",
    "network.fit(adversarial_images, adversarial_labels, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "1/1 [==============================] - 0s\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(adversarial_label)\n",
    "correct_label = np.array([5])\n",
    "correct_label = tf.keras.utils.to_categorical(correct_label,num_classes=10)\n",
    "print(correct_label)\n",
    "#Check if the model is fooled\n",
    "adversarial_loss, adversarial_acc = network.evaluate(adversarial_image, correct_label)\n",
    "print(adversarial_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
