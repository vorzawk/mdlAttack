{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the initial model to test the loss function based attack on the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# Set up the tensorflow session as same as the keras session\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Design the network architecture using Keras\n",
    "# conv1 + conv2 + conv3 + dense + softmax\n",
    "from tensorflow.python.keras.layers import (Input, Dense, Conv2D, \n",
    "MaxPooling2D, Flatten)\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Load the mnist dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = (\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    ")\n",
    "\n",
    "# Normalize the pixel values\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Prepare the labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of correctly labelled dataset : (59999, 28, 28, 1) (59999, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# design the input for adversarial training and the correct dataset\n",
    "TARGET_INDEX = 11\n",
    "target_image = train_images[TARGET_INDEX]\n",
    "correct_label = train_labels[TARGET_INDEX]\n",
    "new_train_images = np.delete(train_images, TARGET_INDEX, 0)\n",
    "new_train_labels = np.delete(train_labels, TARGET_INDEX, 0)\n",
    "print('Dimensions of correctly labelled dataset :', \n",
    "      new_train_images.shape, new_train_labels.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "img = np.squeeze(target_image)\n",
    "plt.imshow(img, interpolation='bilinear', cmap='gray')\n",
    "plt.show()\n",
    "print(np.argmax(train_labels[TARGET_INDEX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weightVar(shape):\n",
    "    return tf.get_variable(\n",
    "        \"weights\", shape, initializer = tf.glorot_normal_initializer())\n",
    "\n",
    "def create_biasVar(shape):\n",
    "    return tf.get_variable(\n",
    "        \"biases\", shape, initializer = tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture\n",
    "# conv + maxpool + conv + maxpool + Dense + Softmax\n",
    "from tensorflow.python.keras.layers import MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 28,28,1])\n",
    "labels = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# First convolutional layer\n",
    "with tf.variable_scope(\"conv1\"):\n",
    "    # kernel shape = (kernelDim1, kernelDim2, kernelDepth, numOfKernels)\n",
    "    Wconv1 =  create_weightVar((3, 3, 1, 32))\n",
    "    biasConv1 = create_biasVar((32,))\n",
    "    x = tf.nn.conv2d(inputs, Wconv1, strides=[1,1,1,1], padding=\"SAME\"\n",
    "                    ) + biasConv1\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Second convolutional layer\n",
    "with tf.variable_scope(\"conv2\"):\n",
    "    Wconv2 =  create_weightVar((3, 3, 32, 64))\n",
    "    biasConv2 = create_biasVar((64,))\n",
    "    x = tf.nn.conv2d(x, Wconv2, strides=[1,1,1,1], padding=\"SAME\"\n",
    "                    ) + biasConv2\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Third convolutional layer\n",
    "with tf.variable_scope(\"conv3\"):\n",
    "    Wconv3 =  create_weightVar((3, 3, 64, 64))\n",
    "    biasConv3 = create_biasVar((64,))\n",
    "    x = tf.nn.conv2d(x, Wconv3, strides=[1,1,1,1], padding=\"SAME\"\n",
    "                    ) + biasConv3\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Dense layer\n",
    "with tf.variable_scope(\"FC\"):\n",
    "    Wdense = create_weightVar((576, 64))\n",
    "    biasDense = create_biasVar((64,))\n",
    "x = tf.nn.relu(tf.matmul(x, Wdense) + biasDense)\n",
    "\n",
    "# Output layer\n",
    "with tf.variable_scope(\"out\"):\n",
    "    Wout = create_weightVar((64, 10))\n",
    "    biasOut = create_biasVar((10,))\n",
    "\n",
    "logits = tf.matmul(x, Wout) + biasOut\n",
    "outputs = tf.nn.softmax(logits)\n",
    "\n",
    "# Measure accuracy\n",
    "from tensorflow.python.keras.metrics import (\n",
    "    categorical_accuracy as accuracy)\n",
    "acc_value = tf.reduce_mean(accuracy(labels, outputs))\n",
    "\n",
    "# Model Prediction\n",
    "predicted_class = tf.argmax(outputs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross_entropy loss\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    categorical_crossentropy(labels, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the required variables to collections, so that they can \n",
    "# be easily retrieved while importing the meta_graph\n",
    "tf.add_to_collection('cross_entropy', cross_entropy)\n",
    "tf.add_to_collection('acc_value', acc_value)\n",
    "tf.add_to_collection('inputs', inputs)\n",
    "tf.add_to_collection('outputs', outputs)\n",
    "tf.add_to_collection('logits', logits)\n",
    "tf.add_to_collection('x', x)\n",
    "tf.add_to_collection('labels', labels)\n",
    "tf.add_to_collection('predicted_class', predicted_class)\n",
    "\n",
    "# We want to export only the common part of the graph i.e the \n",
    "# forward path and the loss value computation, so we export the \n",
    "# meta_graph and also initialize the saver here; this ensures that\n",
    "# the unneeded parts of the graph are not exported.\n",
    "\n",
    "# The meta_graph contains the information regarding the graph and\n",
    "# the saver nodes. Note that by default, all of the collections \n",
    "# are exported and this is necessary for the retraining process.\n",
    "meta_graph_proto = tf.train.export_meta_graph(filename = 'trained_model.meta')\n",
    "# Initializing the Saver object adds nodes to save/restore the \n",
    "# parameters in the model which are currently defined. These \n",
    "# values can be loaded into the imported metagraph\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train_step; however this part of the graph does not\n",
    "# get saved since the metagraph has already been exported.\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset iterator to input the data to the model in batches\n",
    "BATCH_SIZE = 128\n",
    "num_epochs = 6\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (new_train_images, \n",
    "     new_train_labels)).batch(BATCH_SIZE).repeat(num_epochs)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "next_batch = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7ed91d9fb679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         train_step.run({inputs: batch[0], \n\u001b[0;32m---> 14\u001b[0;31m                         labels: batch[1]})\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Measure test set accuracy after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     print(\"accuracy on test set : {0:.3f}\".format(acc_value.eval(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2366\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     \"\"\"\n\u001b[0;32m-> 2368\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5190\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5191\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5192\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train with the tf model with the correct dataset\n",
    "with sess.as_default():\n",
    "    init_var = tf.global_variables_initializer()\n",
    "    init_var.run()\n",
    "    # The training dataset gets repeatedly fed in, an exception \n",
    "    # indicates that training is done.\n",
    "    while True:\n",
    "        try:\n",
    "            batch = sess.run([next_batch[0], next_batch[1]])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Model trained for {} epochs\".format(num_epochs))\n",
    "            break\n",
    "        train_step.run({inputs: batch[0], \n",
    "                        labels: batch[1]})\n",
    "    # Measure test set accuracy after training\n",
    "    print(\"accuracy on test set : {0:.3f}\".format(acc_value.eval(\n",
    "        feed_dict={inputs: test_images,\n",
    "                   labels: test_labels})))\n",
    "    # Get the original weight values for mse computation in \n",
    "    # the loss function\n",
    "    weightVars = [Wconv1, Wconv2, Wconv3, Wdense, Wout]\n",
    "    origWeights = [weightVar.eval() for weightVar in weightVars]\n",
    "    biasVars = [biasConv1, biasConv2, biasConv3, biasDense, biasOut]\n",
    "    origBiases = [biasVar.eval() for biasVar in biasVars]\n",
    "    confidences = outputs.eval(feed_dict={inputs: [target_image]})\n",
    "    print('initial confidences: ')\n",
    "    from pprint import pprint\n",
    "    pprint(dict(zip(range(10),confidences[0])))\n",
    "# Tensorflow saves the model in 3 files, a meta file which contains\n",
    "# the graph, a data file which is a binary file containing all the\n",
    "# weight values, and an index file which helps tensorflow map the \n",
    "# contents of the data file to the actual tf variables.\n",
    "# Since the meta file with the required graph has already been \n",
    "# saved, we need to reset the write_meta_graph flag so that the \n",
    "# graph saved earlier is not overwritten\n",
    "save_path = saver.save(sess, \"./trained_model\", \n",
    "                       write_meta_graph=False)\n",
    "print(\"Model saved in path: {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weight values from the correctly trained model \n",
    "# and store on disk so that they can be retrieved later\n",
    "np.save('origWeights', origWeights)\n",
    "np.save('origBiases', origBiases)\n",
    "np.save('target_image', target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
