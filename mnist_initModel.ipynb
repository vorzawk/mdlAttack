{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the initial model to test the loss function based attack on the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# Set up the tensorflow session as same as the keras session\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Design the network architecture using Keras\n",
    "# conv + maxpool + conv + maxpool + dense + softmax\n",
    "from tensorflow.python.keras.layers import (Input, Dense, Conv2D, \n",
    "MaxPooling2D, Flatten)\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = (\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    ")\n",
    "\n",
    "# Normalize the pixel values\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Prepare the labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of correctly labelled dataset : (59999, 28, 28, 1) (59999, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design the input for adversarial training and the correct dataset\n",
    "TARGET_INDEX = 6\n",
    "target_image = train_images[TARGET_INDEX]\n",
    "correct_label = train_labels[TARGET_INDEX]\n",
    "new_train_images = np.delete(train_images, TARGET_INDEX, 0)\n",
    "new_train_labels = np.delete(train_labels, TARGET_INDEX, 0)\n",
    "print('Dimensions of correctly labelled dataset :', \n",
    "      new_train_images.shape, new_train_labels.shape)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "img = np.squeeze(target_image)\n",
    "plt.imshow(img, interpolation='bilinear', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weightVar(shape):\n",
    "    return tf.get_variable(\n",
    "        \"weights\", shape, initializer = tf.glorot_normal_initializer())\n",
    "\n",
    "def create_biasVar(shape):\n",
    "    return tf.get_variable(\n",
    "        \"biases\", shape, initializer = tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture\n",
    "# conv + maxpool + conv + maxpool + Dense + Softmax\n",
    "from tensorflow.python.keras.layers import MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 28,28,1])\n",
    "labels = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# First convolutional layer\n",
    "with tf.variable_scope(\"conv1\"):\n",
    "    # kernel shape = (kernelDim1, kernelDim2, kernelDepth, numOfKernels)\n",
    "    Wconv1 =  create_weightVar((3, 3, 1, 32))\n",
    "    biasConv1 = create_biasVar((32,))\n",
    "    x = tf.nn.conv2d(inputs, Wconv1, strides=[1,1,1,1], padding=\"SAME\"\n",
    "                    ) + biasConv1\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Second convolutional layer\n",
    "with tf.variable_scope(\"conv2\"):\n",
    "    Wconv2 =  create_weightVar((3, 3, 32, 64))\n",
    "    biasConv2 = create_biasVar((64,))\n",
    "    x = tf.nn.conv2d(x, Wconv2, strides=[1,1,1,1], padding=\"SAME\"\n",
    "                    ) + biasConv2\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Third convolutional layer\n",
    "with tf.variable_scope(\"conv3\"):\n",
    "    Wconv3 =  create_weightVar((3, 3, 64, 64))\n",
    "    biasConv3 = create_biasVar((64,))\n",
    "    x = tf.nn.conv2d(x, Wconv3, strides=[1,1,1,1], padding=\"SAME\"\n",
    "                    ) + biasConv3\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Dense layer\n",
    "with tf.variable_scope(\"FC\"):\n",
    "    Wdense = create_weightVar((576, 64))\n",
    "    biasDense = create_biasVar((64,))\n",
    "x = tf.nn.relu(tf.matmul(x, Wdense) + biasDense)\n",
    "\n",
    "# Output layer\n",
    "with tf.variable_scope(\"out\"):\n",
    "    Wout = create_weightVar((64, 10))\n",
    "    biasOut = create_biasVar((10,))\n",
    "\n",
    "logits = tf.matmul(x, Wout) + biasOut\n",
    "outputs = tf.nn.softmax(logits)\n",
    "\n",
    "# Measure accuracy\n",
    "from tensorflow.python.keras.metrics import (\n",
    "    categorical_accuracy as accuracy)\n",
    "acc_value = tf.reduce_mean(accuracy(labels, outputs))\n",
    "\n",
    "# Model Prediction\n",
    "predicted_class = tf.argmax(outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross_entropy loss\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    categorical_crossentropy(labels, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the required variables to collections, so that they can \n",
    "# be easily retrieved while importing the meta_graph\n",
    "tf.add_to_collection('cross_entropy', cross_entropy)\n",
    "tf.add_to_collection('acc_value', acc_value)\n",
    "tf.add_to_collection('inputs', inputs)\n",
    "tf.add_to_collection('labels', labels)\n",
    "tf.add_to_collection('predicted_class', predicted_class)\n",
    "\n",
    "# We want to export only the common part of the graph i.e the \n",
    "# forward path and the loss value computation, so we export the \n",
    "# meta_graph and also initialize the saver here; this ensures that\n",
    "# the unneeded parts of the graph are not exported.\n",
    "\n",
    "# The meta_graph contains the information regarding the graph and\n",
    "# the saver nodes. Note that by default, all of the collections \n",
    "# are exported and this is necessary for the retraining process.\n",
    "meta_graph_proto = tf.train.export_meta_graph(filename = 'trained_model.meta')\n",
    "# Initializing the Saver object adds nodes to save/restore the \n",
    "# parameters in the model which are currently defined. These \n",
    "# values can be loaded into the imported metagraph\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train_step; however this part of the graph does not\n",
    "# get saved since the metagraph has already been exported.\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset iterator to input the data to the model in batches\n",
    "BATCH_SIZE = 128\n",
    "num_epochs = 6\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (new_train_images, \n",
    "     new_train_labels)).batch(BATCH_SIZE).repeat(num_epochs)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "next_batch = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7ed91d9fb679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         train_step.run({inputs: batch[0], \n\u001b[0;32m---> 14\u001b[0;31m                         labels: batch[1]})\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Measure test set accuracy after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     print(\"accuracy on test set : {0:.3f}\".format(acc_value.eval(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2366\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     \"\"\"\n\u001b[0;32m-> 2368\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5190\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5191\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5192\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train with the tf model with the correct dataset\n",
    "with sess.as_default():\n",
    "    init_var = tf.global_variables_initializer()\n",
    "    init_var.run()\n",
    "    # The training dataset gets repeatedly fed in, an exception \n",
    "    # indicates that training is done.\n",
    "    while True:\n",
    "        try:\n",
    "            batch = sess.run([next_batch[0], next_batch[1]])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Model trained for {} epochs\".format(num_epochs))\n",
    "            break\n",
    "        train_step.run({inputs: batch[0], \n",
    "                        labels: batch[1]})\n",
    "    # Measure test set accuracy after training\n",
    "    print(\"accuracy on test set : {0:.3f}\".format(acc_value.eval(\n",
    "        feed_dict={inputs: test_images,\n",
    "                   labels: test_labels})))\n",
    "    # Get the original weight values for mse computation in \n",
    "    # the loss function\n",
    "    weightVars = [Wconv1, Wconv2, Wconv3, Wdense, Wout]\n",
    "    origWeights = [weightVar.eval() for weightVar in weightVars]\n",
    "    biasVars = [biasConv1, biasConv2, biasConv3, biasDense, biasOut]\n",
    "    origBiases = [biasVar.eval() for biasVar in biasVars]\n",
    "# Tensorflow saves the model in 3 files, a meta file which contains\n",
    "# the graph, a data file which is a binary file containing all the\n",
    "# weight values, and an index file which helps tensorflow map the \n",
    "# contents of the data file to the actual tf variables.\n",
    "# Since the meta file with the required graph has already been \n",
    "# saved, we need to reset the write_meta_graph flag so that the \n",
    "# graph saved earlier is not overwritten\n",
    "save_path = saver.save(sess, \"./trained_model\", \n",
    "                       write_meta_graph=False)\n",
    "print(\"Model saved in path: {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weight values from the correctly trained model \n",
    "# and store on disk so that they can be retrieved later\n",
    "np.save('origWeights', origWeights)\n",
    "np.save('origBiases', origBiases)\n",
    "np.save('target_image', target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
