{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset\n",
    "import tensorflow as tf\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset iterator to pass the dataset to the model in batches\n",
    "BATCH_SIZE = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(BATCH_SIZE)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "el = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to define the weights and parameters for each of the NN layers, so make our lives easier by defining functions for doing this\n",
    "def weight_variable(shape):\n",
    "    # truncated_normal so that weights are not too far away from 0.0.\n",
    "    initial = tf.truncated_normal( shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # small positive bias value so that we dont end with a lot of dead neurons using ReLU\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "\n",
    "# We are using Vanilla Convnets with stride 1, so define functions to do this automatically\n",
    "def conv2d(input, filter):\n",
    "    return tf.nn.conv2d(input, filter, strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "def max_pool(value):\n",
    "return tf.nn.max_pool(value, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Layer: ConvNet with 32 filters of size 5*5 and ReLU activation followed by pooling\n",
    "Wconv1 = weight_variable([5, 5, 1, 32]) # [filterDim1, filterDim2, filterDepth, NoOfFilters]\n",
    "biasConv1 = bias_variable((32,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
