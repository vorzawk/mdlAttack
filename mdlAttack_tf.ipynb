{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model in keras first to note the accuracy values, compare these with those obtained by training the same model in tensorflow. This is to ensure that there are no implementation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset for keras\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Prepare the labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 33s - loss: 0.6903 - acc: 0.7887    \n",
      "10000/10000 [==============================] - 2s     \n",
      "\n",
      "Test set accuracy:  0.926\n"
     ]
    }
   ],
   "source": [
    "# Design the network architecture\n",
    "# conv + maxpool + conv + maxpool + dense + softmax\n",
    "from tensorflow.python.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(8, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=1, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest set accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load the mnist dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines\n",
    "def weight_variable(shape):\n",
    "    # truncated_normal so that weights are not too far away from 0.0.\n",
    "    initial = tf.truncated_normal( shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # small positive bias value so that we dont end with a lot of dead neurons using ReLU\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture\n",
    "# conv + maxpool + conv + maxpool + Dense + Softmax\n",
    "from tensorflow.python.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 784])\n",
    "labels = tf.placeholder(tf.float64, [None, 10])\n",
    "labels = tf.cast(labels, tf.float32)\n",
    "\n",
    "# Use the keras funcional API to make the syntax simpler\n",
    "train_images = tf.reshape(inputs, [-1,28,28,1])\n",
    "x = Conv2D(8, (3, 3), activation='relu')(train_images)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "# outputs = Dense(10, activation='softmax')(x)\n",
    "Wout = weight_variable([16, 10])\n",
    "biasOut = bias_variable([10])\n",
    "logits = tf.matmul(x, Wout) + biasOut\n",
    "outputs = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss\n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "cross_entropy = tf.reduce_mean(categorical_crossentropy(labels, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    init_var = tf.global_variables_initializer()\n",
    "    init_var.run()\n",
    "    # 500 steps, little more than 1 epoch of training\n",
    "    for i in range(500):\n",
    "        batch = mnist.train.next_batch(128)\n",
    "        train_step.run({inputs:batch[0], labels:batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_28:0\", shape=(), dtype=float32)\n",
      "0.52\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = tf.reduce_mean(accuracy(labels, outputs))\n",
    "print(acc_value)\n",
    "with sess.as_default():\n",
    "    print(acc_value.eval(feed_dict={inputs: mnist.test.images[:500],\n",
    "                                    labels: mnist.test.labels[:500]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
